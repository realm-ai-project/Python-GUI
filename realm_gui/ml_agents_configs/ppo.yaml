default_settings:
  trainer_type: ppo
  hyperparameters:
    batch_size: 256
    buffer_size: 4096
    learning_rate: 3e-4
    learning_rate_schedule: linear
    # ppo-specific config
    beta: 5.0e-3
    epsilon: 0.2
    lambd: 0.95
    num_epoch: 3
  network_settings:
    normalize: false
    hidden_units: 512
    num_layers: 2
  reward_signals:
    extrinsic:
      gamma: 0.99
      strength: 1.0
    curiosity:
        strength: 0.02
        gamma: 0.99
        encoding_size: 256
        learning_rate: 3.0e-4
  keep_checkpoints: 5
  max_steps: 1e9
  time_horizon: 128
  summary_freq: 50000
  threaded: true